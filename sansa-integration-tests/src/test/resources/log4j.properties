# Root logger option
log4j.rootLogger=info, stdout

# Direct log messages to a log file
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=file:///tmp/spark-reasoner/logging.log
log4j.appender.file.MaxFileSize=10MB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %C{1}:%L - %m%n

# Direct log messages to stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %C{1}:%L - %m%n

log4j.logger.org.apache.http.impl.execchain.RetryExec=ERROR

log4j.logger.akka.event.slf4j.Slf4jLogger=ERROR
log4j.logger.akka.remote.Remoting=ERROR
log4j.logger.org.spark_project.jetty.server=ERROR
log4j.logger.org.apache.spark=ERROR
log4j.logger.org.spark_project.jetty=ERROR
log4j.logger.org.apache.hadoop=ERROR

log4j.logger.org.apache.spark.sql.catalyst.rules.RuleExecutor=TRACE

# Silence akka remoting
log4j.logger.Remoting=WARN

# Ignore messages below warning level from Jetty, because it's a bit verbose
log4j.logger.org.eclipse.jetty=WARN

# HIVE logging used in DataFrame test cases
log4j.logger.org.apache.hadoop.hive=ERROR
log4j.logger.org.apache.derby=ERROR

# our log level
log4j.logger.org.sansa_stack.rdf.spark.io=DEBUG

log4j.logger.org.apache.jena=WARN
log4j.logger.org.apache.jena.hadoop.rdf.io.input.readers=ERROR
